import sys
import re
import random
import pickle
import numpy as np
import tensorflow as tf
from PySide6.QtWidgets import QApplication, QWidget, QVBoxLayout, QLineEdit, QPushButton, QTextEdit, QSlider, QComboBox, QLabel
from PySide6.QtCore import Qt
import os
import webbrowser

greetings = [r"\bì•ˆë…•\b", r"\bì•ˆë…•í•˜ì„¸ìš”\b", r"\bë°˜ê°€ì›Œ\b", r"\bí•˜ì´\b", r"\bì˜ ì§€ë‚´\b"]
greeting_responses = ["ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š", "ë°˜ê°‘ìŠµë‹ˆë‹¤!", "ì•ˆë…•! ì¢‹ì€ í•˜ë£¨ ë³´ë‚´!", "í•˜ì´~ ë­ ë„ì™€ì¤„ê¹Œ?"]

name_questions = [r"\bì´ë¦„ì´ ë­ì•¼\b", r"\bë„ˆ ëˆ„êµ¬ì•¼\b", r"\bë„ˆì˜ ì´ë¦„ì€\b", r"\bë„ˆ ë­ì•¼\b"]
name_responses = ["ë‚´ ì´ë¦„ì€ ë§ˆìŒì´ì•¼!", "ë‚œ ì±—ë´‡ ë§ˆìŒì´ì•¼, ë°˜ê°€ì›Œ!", "ë§ˆìŒì´ë¼ê³  ë¶ˆëŸ¬ì¤˜! ğŸ˜Š"]



def load_model(model_name):
    global tokenizer

   
    if hasattr(sys, '_MEIPASS'):
        base_path = sys._MEIPASS  
    else:
        base_path = os.path.abspath('.')  

    
    if model_name == "ê¸°ë³¸ ëª¨ë¸":
        model_path = os.path.join(base_path, "seq2seq_model_50000.h5")
    elif model_name == "ê³ ê¸‰ ëª¨ë¸":
        model_path = os.path.join(base_path, "seq2seq_model_90000.h5")
    elif model_name == "ë¹ ë¥¸ ëª¨ë¸":
        model_path = os.path.join(base_path, "seq2seq_model_98000.h5")
    else:
        raise ValueError("ëª¨ë¸ ì´ë¦„ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    
    model = tf.keras.models.load_model(model_path)

   
    tokenizer_path = os.path.join(base_path, "tokenizer.pkl")
    with open(tokenizer_path, "rb") as f:
        tokenizer = pickle.load(f)

    return model, tokenizer



model, tokenizer = load_model("ê¸°ë³¸ ëª¨ë¸")

start_token = "<start>"
end_token = "<end>"


encoder_inputs = model.input[0]
encoder_embedding = model.layers[2]
encoder_gru = model.layers[4]
encoder_outputs, state_h = encoder_gru(encoder_embedding(encoder_inputs))
encoder_model = tf.keras.Model(encoder_inputs, [encoder_outputs, state_h])


decoder_inputs = model.input[1]
decoder_embedding = model.layers[3]
decoder_state_input_h = tf.keras.Input(shape=(136,))
decoder_embedded = decoder_embedding(decoder_inputs)
decoder_gru = model.layers[5]
decoder_outputs, decoder_state_h = decoder_gru(decoder_embedded, initial_state=decoder_state_input_h)
decoder_dense = model.layers[6]
decoder_outputs = decoder_dense(decoder_outputs)
decoder_model = tf.keras.Model([decoder_inputs, decoder_state_input_h], [decoder_outputs, decoder_state_h])


def is_greeting(text):
    return any(re.search(pattern, text.lower()) for pattern in greetings)

def is_name_question(text):
    return any(re.search(pattern, text.lower()) for pattern in name_questions)

def chatbot_response(user_input, temperature=0.7):
    if is_greeting(user_input):
        return random.choice(greeting_responses)
    elif is_name_question(user_input):
        return random.choice(name_responses)
    
    
    response = chat_with_model(user_input, temperature)  
    return response


def chat_with_model(input_text, temperature):
    input_seq = tokenizer.texts_to_sequences([input_text])
    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=40, padding="post")

    encoder_output, state_h = encoder_model.predict(input_seq)
    target_seq = np.array([[tokenizer.word_index[start_token]]])
    stop_condition = False
    decoded_sentence = ""
    prev_words = []

    max_output_length = 58
    while not stop_condition:
        output_tokens, h = decoder_model.predict([target_seq, state_h])
        preds = np.asarray(output_tokens[0, -1, :]).astype("float64")
        preds = np.log(preds + 1e-8) / temperature
        exp_preds = np.exp(preds)
        preds = exp_preds / np.sum(exp_preds)

        sampled_token_index = np.random.choice(len(preds), p=preds)
        sampled_word = tokenizer.index_word.get(sampled_token_index, "")

        if not sampled_word or sampled_word in prev_words:
            continue

        prev_words.append(sampled_word)
        if len(prev_words) > 3:
            prev_words.pop(0)

        if sampled_word == end_token or len(decoded_sentence.split()) >= max_output_length:
            stop_condition = True
        else:
            decoded_sentence += " " + sampled_word

        target_seq = np.array([[sampled_token_index]])
        state_h = h

    return decoded_sentence.strip()


class ChatWindow(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Chatbot Shell")
        self.setGeometry(100, 100, 600, 400)
        layout = QVBoxLayout()

        
        self.model_selector = QComboBox(self)
        self.model_selector.addItem("ê¸°ë³¸ ëª¨ë¸")
        self.model_selector.addItem("ê³ ê¸‰ ëª¨ë¸")
        self.model_selector.addItem("ë¹ ë¥¸ ëª¨ë¸")
        self.model_selector.currentTextChanged.connect(self.change_model)

       
        self.chat_area = QTextEdit(self)
        self.chat_area.setReadOnly(True)
        self.chat_area.setStyleSheet("background-color: #1e1e1e; color: white; padding: 10px; border-radius: 5px;")

        self.text_input = QLineEdit(self)
        self.text_input.setPlaceholderText("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
        self.text_input.returnPressed.connect(self.send_message)

        self.send_button = QPushButton("ë³´ë‚´ê¸°", self)
        self.send_button.clicked.connect(self.send_message)

        self.temperature_slider = QSlider(Qt.Horizontal)
        self.temperature_slider.setMinimum(10)
        self.temperature_slider.setMaximum(100)
        self.temperature_slider.setValue(70)
        self.temperature_slider.valueChanged.connect(self.update_temperature)
        self.temperature_label = QLabel(f"Temperature: {self.temperature_slider.value() / 100:.2f}", self)

        layout.addWidget(QLabel("ëª¨ë¸ ì„ íƒ:"))
        layout.addWidget(self.model_selector)
        layout.addWidget(self.temperature_label)
        layout.addWidget(self.temperature_slider)
        layout.addWidget(self.chat_area)
        layout.addWidget(self.text_input)
        layout.addWidget(self.send_button)

        self.setLayout(layout)
        self.apply_dark_mode()

        self.model_name = "ê¸°ë³¸ ëª¨ë¸"
        self.model, self.tokenizer = load_model(self.model_name)

    def change_model(self, model_name):
        global model, tokenizer
        model, tokenizer = load_model(model_name) 
        self.model_name = model_name  
        self.display_message(f"ëª¨ë¸ì´ '{model_name}'ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\n", "bot")

    

    def send_message(self):
        user_message = self.text_input.text().strip()
        if not user_message:
            return

        if user_message.lower() == "clear":
            self.chat_area.clear() 
            self.display_message("ëŒ€í™” ë‚´ìš©ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n", "bot")
            self.text_input.clear()
            return
    
        if user_message.lower() in ["/?", "/help"]:
            help_message = (
                "ì‚¬ìš©ë²•:\n"
                "/? ë˜ëŠ” /help: ì‚¬ìš©ë²•ì„ í‘œì‹œí•©ë‹ˆë‹¤.\n"
                "ê²€ìƒ‰ [ê²€ìƒ‰ì–´]: êµ¬ê¸€ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n"
                "clear: ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”\n"
                "ì¼ë°˜ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ë©´ ì±—ë´‡ê³¼ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
            self.display_message(help_message, "bot")
            self.text_input.clear()
            return

        if "ê²€ìƒ‰" in user_message: 
            search_query = user_message.replace("ê²€ìƒ‰", "").strip() 
            if search_query:  
                search_url = f"https://www.google.com/search?q={search_query}"
                webbrowser.open(search_url)  
                self.display_message(f"êµ¬ê¸€ì—ì„œ '{search_query}' ê²€ìƒ‰ ì¤‘...\n", "bot")
            else:
                self.display_message("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n", "bot")
            self.text_input.clear()
            return

        self.display_message(f"You: {user_message}\n", "user")
        response = chatbot_response(user_message, self.temperature_slider.value() / 100)
        self.display_message(f"ë§ˆìŒì´: {response}\n", "bot")
        self.text_input.clear()




    def display_message(self, message, sender):
        self.chat_area.append(message)
        self.chat_area.verticalScrollBar().setValue(self.chat_area.verticalScrollBar().maximum())

    def update_temperature(self):
        temp = self.temperature_slider.value() / 100
        self.temperature_label.setText(f"Temperature: {temp:.2f}")

    def change_model(self, model_name):
        global model, tokenizer
        model, tokenizer = load_model(model_name)

    def apply_dark_mode(self):
        self.setStyleSheet("""
            QWidget { background-color: #2b2b2b; color: white; }
            QLineEdit, QPushButton { background-color: #444444; color: white; border: 1px solid #888888; }
            QLabel { color: white; }
        """)

if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = ChatWindow()
    window.show()
    sys.exit(app.exec())
