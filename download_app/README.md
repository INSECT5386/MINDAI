```bash
import sys
import re
import random
import pickle
import numpy as np
import tensorflow as tf
import tkinter as tk
from tkinter import scrolledtext
import os
import webbrowser

# ì¸ì‚¬ íŒ¨í„´ ë° ì‘ë‹µ
greetings = [r"\bì•ˆë…•\b", r"\bì•ˆë…•í•˜ì„¸ìš”\b", r"\bë°˜ê°€ì›Œ\b", r"\bí•˜ì´\b", r"\bì˜ ì§€ë‚´\b"]
greeting_responses = ["ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š", "ë°˜ê°‘ìŠµë‹ˆë‹¤!", "ì•ˆë…•! ì¢‹ì€ í•˜ë£¨ ë³´ë‚´!", "í•˜ì´~ ë­ ë„ì™€ì¤„ê¹Œ?"]

name_questions = [r"\bì´ë¦„ì´ ë­ì•¼\b", r"\bë„ˆ ëˆ„êµ¬ì•¼\b", r"\bë„ˆì˜ ì´ë¦„ì€\b", r"\bë„ˆ ë­ì•¼\b"]
name_responses = ["ë‚´ ì´ë¦„ì€ ë§ˆìŒì´ì•¼!", "ë‚œ ì±—ë´‡ ë§ˆìŒì´ì•¼, ë°˜ê°€ì›Œ!", "ë§ˆìŒì´ë¼ê³  ë¶ˆëŸ¬ì¤˜! ğŸ˜Š"]


def load_model(model_name):
    global tokenizer

    # PyInstallerì—ì„œ EXEê°€ ì‹¤í–‰ë  ë•Œ, ì„ì‹œ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    if hasattr(sys, '_MEIPASS'):
        base_path = sys._MEIPASS  # EXEë¡œ ì‹¤í–‰ë  ê²½ìš°
    else:
        base_path = os.path.abspath('.')  # ê°œë°œ í™˜ê²½ì—ì„œ ì‹¤í–‰ë  ê²½ìš°

  
    if model_name == "ê¸°ë³¸ ëª¨ë¸":
        model_path = os.path.join(base_path, "seq2seq_model_90000.h5")
    elif model_name == "ê³ ê¸‰ ëª¨ë¸":
        model_path = os.path.join(base_path, "seq2seq_model_98000.h5")
    else:
        raise ValueError("ëª¨ë¸ ì´ë¦„ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # ëª¨ë¸ ë¡œë“œ
    model = tf.keras.models.load_model(model_path)

    # í† í¬ë‚˜ì´ì € íŒŒì¼ ê²½ë¡œ ì„¤ì •
    tokenizer_path = os.path.join(base_path, "tokenizer.pkl")
    with open(tokenizer_path, "rb") as f:
        tokenizer = pickle.load(f)

    return model, tokenizer


# ì´ˆê¸° ëª¨ë¸ ì„¤ì • (ê¸°ë³¸ ëª¨ë¸)
model, tokenizer = load_model("ê¸°ë³¸ ëª¨ë¸")

start_token = "<start>"
end_token = "<end>"

# ì¸ì½”ë” ëª¨ë¸ ìƒì„±
encoder_inputs = model.input[0]
encoder_embedding = model.layers[2]
encoder_gru = model.layers[4]
encoder_outputs, state_h = encoder_gru(encoder_embedding(encoder_inputs))
encoder_model = tf.keras.Model(encoder_inputs, [encoder_outputs, state_h])

# ë””ì½”ë” ëª¨ë¸ ìƒì„±
decoder_inputs = model.input[1]
decoder_embedding = model.layers[3]
decoder_state_input_h = tf.keras.Input(shape=(136,))
decoder_embedded = decoder_embedding(decoder_inputs)
decoder_gru = model.layers[5]
decoder_outputs, decoder_state_h = decoder_gru(decoder_embedded, initial_state=decoder_state_input_h)
decoder_dense = model.layers[6]
decoder_outputs = decoder_dense(decoder_outputs)
decoder_model = tf.keras.Model([decoder_inputs, decoder_state_input_h], [decoder_outputs, decoder_state_h])

# ì¸ì‚¬ ì²´í¬ í•¨ìˆ˜
def is_greeting(text):
    return any(re.search(pattern, text.lower()) for pattern in greetings)

def is_name_question(text):
    return any(re.search(pattern, text.lower()) for pattern in name_questions)

def chatbot_response(user_input, temperature=0.7):
    if is_greeting(user_input):
        return random.choice(greeting_responses)
    elif is_name_question(user_input):
        return random.choice(name_responses)
    
    # Seq2Seq ëª¨ë¸ ì‚¬ìš©
    response = chat_with_model(user_input, temperature)  
    return response

# Seq2Seq ëª¨ë¸ì„ ì‚¬ìš©í•œ ì±„íŒ… ì‘ë‹µ í•¨ìˆ˜
def chat_with_model(input_text, temperature):
    input_seq = tokenizer.texts_to_sequences([input_text])
    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=40, padding="post")

    encoder_output, state_h = encoder_model.predict(input_seq)
    target_seq = np.array([[tokenizer.word_index[start_token]]])
    stop_condition = False
    decoded_sentence = ""
    prev_words = []

    max_output_length = 58
    while not stop_condition:
        output_tokens, h = decoder_model.predict([target_seq, state_h])
        preds = np.asarray(output_tokens[0, -1, :]).astype("float64")
        preds = np.log(preds + 1e-8) / temperature
        exp_preds = np.exp(preds)
        preds = exp_preds / np.sum(exp_preds)

        sampled_token_index = np.random.choice(len(preds), p=preds)
        sampled_word = tokenizer.index_word.get(sampled_token_index, "")

        if not sampled_word or sampled_word in prev_words:
            continue

        prev_words.append(sampled_word)
        if len(prev_words) > 3:
            prev_words.pop(0)

        if sampled_word == end_token or len(decoded_sentence.split()) >= max_output_length:
            stop_condition = True
        else:
            decoded_sentence += " " + sampled_word

        target_seq = np.array([[sampled_token_index]])
        state_h = h

    return decoded_sentence.strip()

class ChatWindow(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("Chatbot Shell")
        self.geometry("600x500")
        self.config(bg="#f4f4f4")

        # ìƒë‹¨ ì œëª© í‘œì‹œ
        self.header_label = tk.Label(self, text="ë§ˆìŒì´ ì±—ë´‡", font=("Helvetica", 18, "bold"), fg="#2c3e50", bg="#f4f4f4")
        self.header_label.pack(pady=10)

        # ëª¨ë¸ ì„ íƒ
        self.model_selector = tk.StringVar(self)
        self.model_selector.set("ê¸°ë³¸ ëª¨ë¸")
        self.model_menu = tk.OptionMenu(self, self.model_selector, "ê¸°ë³¸ ëª¨ë¸", "ê³ ê¸‰ ëª¨ë¸", command=self.change_model)
        self.model_menu.config(width=15, font=("Helvetica", 12), bg="#3498db", fg="white")
        self.model_menu.pack(pady=10)

        # ëŒ€í™”ì°½ (ìŠ¤í¬ë¡¤í…ìŠ¤íŠ¸)
        self.chat_area = scrolledtext.ScrolledText(self, wrap=tk.WORD, height=15, width=70, state=tk.DISABLED, bg="#1e1e1e", fg="white", font=("Courier", 12))
        self.chat_area.pack(padx=20, pady=10)

        # ì‚¬ìš©ì ì…ë ¥ í•„ë“œ
        self.text_input = tk.Entry(self, width=50, font=("Helvetica", 12))
        self.text_input.pack(pady=10)
        self.text_input.bind("<Return>", self.send_message)

        # ì „ì†¡ ë²„íŠ¼
        self.send_button = tk.Button(self, text="ë³´ë‚´ê¸°", command=self.send_message, font=("Helvetica", 12), bg="#2ecc71", fg="white", width=10)
        self.send_button.pack(pady=5)

        # Temperature ìŠ¬ë¼ì´ë”
        self.temperature_slider = tk.Scale(self, from_=0, to=100, orient="horizontal", length=200, label="Temperature", font=("Helvetica", 12))
        self.temperature_slider.set(70)
        self.temperature_slider.pack(pady=10)

    def change_model(self, model_name):
        global model, tokenizer
        model, tokenizer = load_model(model_name)
        self.display_message(f"ëª¨ë¸ì´ '{model_name}'ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\n", "bot")

    def send_message(self, event=None):
        user_message = self.text_input.get().strip()
        if not user_message:
            return

        if user_message.lower() == "clear":
            self.chat_area.config(state=tk.NORMAL)
            self.chat_area.delete(1.0, tk.END)
            self.chat_area.config(state=tk.DISABLED)
            self.display_message("ëŒ€í™” ë‚´ìš©ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n", "bot")
            self.text_input.delete(0, tk.END)
            return
        
        if user_message.lower() in ["/?", "/help"]:
            help_message = (
                "ì‚¬ìš©ë²•:\n"
                "/? ë˜ëŠ” /help: ì‚¬ìš©ë²•ì„ í‘œì‹œí•©ë‹ˆë‹¤.\n"
                "ê²€ìƒ‰ [ê²€ìƒ‰ì–´]: êµ¬ê¸€ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n"
                "clear: ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”\n"
                "ì¼ë°˜ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ë©´ ì±—ë´‡ê³¼ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
            self.display_message(help_message, "bot")
            self.text_input.delete(0, tk.END)
            return

        if "ê²€ìƒ‰" in user_message:  # 'ê²€ìƒ‰'ì´ í¬í•¨ëœ ì…ë ¥ ì²˜ë¦¬
            search_query = user_message.replace("ê²€ìƒ‰", "").strip()  # 'ê²€ìƒ‰' ë‹¨ì–´ ì œê±°í•˜ê³  ê²€ìƒ‰ì–´ ì¶”ì¶œ
            if search_query:  # ê²€ìƒ‰ì–´ê°€ ë¹„ì–´ ìˆì§€ ì•Šìœ¼ë©´
                self.display_message(f"ê²€ìƒ‰ì–´ '{search_query}'ê°€ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n", "user")  # ëŒ€í™”ì°½ì— ì‚¬ìš©ì ì…ë ¥ í‘œì‹œ
                search_url = f"https://www.google.com/search?q={search_query}"
                webbrowser.open(search_url)  # êµ¬ê¸€ì—ì„œ ê²€ìƒ‰
                self.display_message(f"êµ¬ê¸€ì—ì„œ '{search_query}' ê²€ìƒ‰ ì¤‘...\n", "bot")
            else:
                self.display_message("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n", "bot")
            self.text_input.delete(0, tk.END)
            return


        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
        self.display_message(f"{user_message}\n", "user")

        # ì±—ë´‡ ì‘ë‹µ ì¶œë ¥
        response = chatbot_response(user_message, self.temperature_slider.get() / 100)
        self.display_message(f"{response}\n", "bot")  # 'ë§ˆìŒì´:'ëŠ” ì´ë¯¸ display_messageì—ì„œ ì²˜ë¦¬ë¨
        
        self.text_input.delete(0, tk.END)

    def display_message(self, message, sender):
        self.chat_area.config(state=tk.NORMAL)
        if sender == "user":
            self.chat_area.insert(tk.END, f"You: {message}\n", "user")
        elif sender == "bot":
            self.chat_area.insert(tk.END, f"ë§ˆìŒì´: {message}\n", "bot")
        self.chat_area.config(state=tk.DISABLED)
        self.chat_area.yview(tk.END)


if __name__ == "__main__":
    app = ChatWindow()
    app.mainloop()
